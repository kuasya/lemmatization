# Задача лемматизации
Большие данные и машинное обучение в когнитивных науках

## Описание
1. Используя язык программирования Python 3 необходимо выполнить предобработку текстовых данных:
- привести все слова к нижнему регистру;
- удалить пунктуацию;
- удалить нерелевантные слова (ссылки, слова на английском, и. т .д);
- удалить стоп слова с помощью готовых словарей ( при необходимости дополнить словарь);
- выполнить лемматизацию ( привести все слова в их начальную словоформу).
2. Отсортировать слова по частоте их употребления и выделить топ 100 слов.
Данные: Результаты поисковых запросов по теме «Благотворительность», собранных системой мониторинга «Крибрум».

## Решение
Язык программирования: Python 3.8
Используемые библиотеки: re, pymorphy2, nltk

Лемматизацию слов выполняю с помощью Pymorphy2, для морфологического анализа использую класс MorphAnalyzer.
![image](https://user-images.githubusercontent.com/62285192/220194254-78b8c282-71e0-42a9-a42c-f84161161233.png)

 
Для удаления стоп-слов использую библиотеку NLTK. Также добавила в список несколько новых слов, которые, как мне кажется, тоже относятся к разряду «стоп-слов».

![image](https://user-images.githubusercontent.com/62285192/220194323-90bd0d42-7719-4260-a6d9-db4454b66429.png)

 
Считываю данные построчно и для упрощения работы нахожу слова, написанные кириллицей, применяя метод findall библиотеки re - поиск по шаблону.

![image](https://user-images.githubusercontent.com/62285192/220194365-33cbb19e-257f-40ae-be44-78e7d25031f6.png)

 
Привожу каждое слово в строке к нижнему регистру. Используя метод normal_forms, который возвращает список нормальных форм заданного слова, получаю исходную форму рассматриваемого слова.

![image](https://user-images.githubusercontent.com/62285192/220194414-b22476c0-b21f-4cb4-b532-f8732f1aadc9.png)

 
Также веду подсчет слов: словарь dict_words, каждому слову соответствует число встреч данного слова в тексте. Словарь dict_count подсчитывает, сколько в тексте слов, встречающихся n-ое количество раз. 
В процессе работы с новыми словами происходит обновление словарей.

![image](https://user-images.githubusercontent.com/62285192/220194460-8f3a5e5f-55d2-43a1-9c71-cf6747401c7d.png)

 
Список lst_count в порядке убывания (от наиболее часто употребляемого слова) содержит число встреч слова в тексте, чтобы в дальнейшем по данному значению можно было найти слова из словаря dict_words. 

По условию оставляем только 100 наиболее встречающихся слов.

![image](https://user-images.githubusercontent.com/62285192/220194514-9baab288-8cd5-4e11-bccd-753b8b0170b6.png)

 
Используя полученный список lst_count, нахожу в словаре dict_words по паре ключ-значение 100 наиболее употребляемых слов. Слова (в порядке убывания по частоте употребления) записываю в список lst_count_new.

![image](https://user-images.githubusercontent.com/62285192/220194574-201469ee-9ba1-4ae8-aa90-e772a21c9ad6.png)

 
В файле result_task.txt приведен полученный результат «топ 100 слов».
В зависимости от списка «стоп-слов» результат может немного различаться.



