# lemmatization

Этап 1
1. Используя язык программирования Python 3 необходимо выполнить предобработку текстовых данных:
- привести все слова к нижнему регистру;
- удалить пунктуацию;
- удалить нерелевантные слова (ссылки, слова на английском, и. т .д);
- удалить стоп слова с помощью готовых словарей ( при необходимости дополнить словарь);
- выполнить лемматизацию ( привести все слова в их начальную словоформу).
2. Отсортировать слова по частоте их употребления и выделить топ 100 слов.
Данные: Результаты поисковых запросов по теме «Благотворительность», собранных системой мониторинга «Крибрум».

## Решение
Язык программирования: Python 3.8
Используемые библиотеки: re, pymorphy2, nltk
Лемматизацию слов выполняю с помощью Pymorphy2, для морфологического анализа использую класс MorphAnalyzer.
![image](https://user-images.githubusercontent.com/62285192/220194254-78b8c282-71e0-42a9-a42c-f84161161233.png)

 
Для удаления стоп-слов использую библиотеку NLTK. Также добавила в список несколько новых слов, которые, как мне кажется, тоже относятся к разряду «стоп-слов».

![image](https://user-images.githubusercontent.com/62285192/220194323-90bd0d42-7719-4260-a6d9-db4454b66429.png)

 
Считываю данные построчно и для упрощения работы нахожу слова, написанные кириллицей, применяя метод findall библиотеки re - поиск по шаблону.

![image](https://user-images.githubusercontent.com/62285192/220194365-33cbb19e-257f-40ae-be44-78e7d25031f6.png)

 
Привожу каждое слово в строке к нижнему регистру. Используя метод normal_forms, который возвращает список нормальных форм заданного слова, получаю исходную форму рассматриваемого слова.

![image](https://user-images.githubusercontent.com/62285192/220194414-b22476c0-b21f-4cb4-b532-f8732f1aadc9.png)

 
Также веду подсчет слов: словарь dict_words, каждому слову соответствует число встреч данного слова в тексте. Словарь dict_count подсчитывает, сколько в тексте слов, встречающихся n-ое количество раз. 
В процессе работы с новыми словами происходит обновление словарей.

![image](https://user-images.githubusercontent.com/62285192/220194460-8f3a5e5f-55d2-43a1-9c71-cf6747401c7d.png)

 
Список lst_count в порядке убывания (от наиболее часто употребляемого слова) содержит число встреч слова в тексте, чтобы в дальнейшем по данному значению можно было найти слова из словаря dict_words. 

По условию оставляем только 100 наиболее встречающихся слов.

![image](https://user-images.githubusercontent.com/62285192/220194514-9baab288-8cd5-4e11-bccd-753b8b0170b6.png)

 
Используя полученный список lst_count, нахожу в словаре dict_words по паре ключ-значение 100 наиболее употребляемых слов. Слова (в порядке убывания по частоте употребления) записываю в список lst_count_new.

![image](https://user-images.githubusercontent.com/62285192/220194574-201469ee-9ba1-4ae8-aa90-e772a21c9ad6.png)

 
Ниже привожу полученный результат «топ 100 слов».
В зависимости от списка «стоп-слов» результат может немного различаться.

год
человек
весь
день
всё
благотворительный
мочь
ребёнок
помощь
жизнь
время
показать
полностью
стать
деньга
дело
ещё
добрый
каждый
очень
друг
новый
россия
фонд
помочь
дом
большой
должный
хороший
первый
мир
работа
доброта
благотворительность
делать
самый
проект
семья
организация
просто
сделать
также
нужно
иметь
говорить
слово
хотеть
сказать
праздник
участие
сегодня
группа
место
февраль
сбор
помогать
дать
город
получить
рубль
знать
любой
спасибо
средство
сумма
мероприятие
пара
нужный
сила
давать
карта
отец
вопрос
счёт
возможность
март
рука
несколько
поддержка
страна
работать
принять
женщина
иоанн
пройти
являться
история
больший
пока
жить
русский
добро
книга
любовь
вещь
огромный
проявление
цель
право
центр


